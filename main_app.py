# main_app.py (FINAL CORE CODE - DO NOT EDIT THIS FILE AGAIN)

from ultralytics import YOLO
import cv2
import mediapipe as mp
import numpy as np
import csv
import os

# --- 1. Setup Models and Libraries ---
model = YOLO('yolov8n.pt') 
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)

# --- 2. Setup Data Collection ---
DATA_PATH = os.path.join('Action_Data') # Folder to store collected data

# !!! IMPORTANT CHANGE: Get action name from environment variable set by the record scripts !!!
action_name = os.environ.get('ACTION_NAME', 'Unknown_Action') 

num_coords = 33 

# Create the data folder if it doesn't exist
os.makedirs(DATA_PATH, exist_ok=True)

# Function to extract landmark coordinates (33 joints * 3 coords = 99 features)
def extract_keypoints(results):
    if results.pose_landmarks:
        return np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten()
    return np.zeros(num_coords*3) 

# Setup CSV Header (only runs ONCE)
csv_file = os.path.join(DATA_PATH, 'coords.csv')
if not os.path.exists(csv_file):
    print("Creating CSV header...")
    header = ['action']
    for val in range(1, num_coords + 1):
        header += [f'x{val}', f'y{val}', f'z{val}']
    with open(csv_file, mode='w', newline='') as f:
        csv_writer = csv.writer(f, delimiter=',')
        csv_writer.writerow(header)

# --- 3. Start Webcam Stream ---
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("Error: Could not open webcam.")
    exit()
    
print(f"--- READY TO COLLECT DATA FOR: {action_name} ---")
print("Press 'q' to quit.")

# --- 4. Process Frames and Save Data ---
with open(csv_file, mode='a', newline='') as f:
    csv_writer = csv.writer(f, delimiter=',')
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # 4.1. Get person bounding box using YOLO
        results = model.track(frame, persist=True, classes=0, tracker="bytetrack.yaml", verbose=False)
        
        # Get the region of the person (the ROI)
        pose_results = None
        if results[0].boxes.id is not None:
            boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)
            
            if len(boxes) > 0:
                x_min, y_min, x_max, y_max = boxes[0] 
                person_roi = frame[y_min:y_max, x_min:x_max]
                
                # 4.2. Process ROI for Pose Estimation
                img_rgb = cv2.cvtColor(person_roi, cv2.COLOR_BGR2RGB)
                pose_results = pose.process(img_rgb)
                
                # 4.3. Draw Landmarks and Log Data
                if pose_results.pose_landmarks:
                    mp.solutions.drawing_utils.draw_landmarks(
                        person_roi, 
                        pose_results.pose_landmarks, 
                        mp_pose.POSE_CONNECTIONS)
                    
                    # 4.4. DATA LOGGING (Saves one row per frame)
                    keypoints = extract_keypoints(pose_results)
                    row = [action_name] + keypoints.tolist()
                    csv_writer.writerow(row)
                    
                    # Display recording status on screen
                    cv2.putText(frame, f'RECORDING: {action_name}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
            
        # Display the result
        annotated_frame = results[0].plot()
        cv2.imshow(f"Real-Time Security Monitor (Data Collection for {action_name})", annotated_frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

# --- 5. Cleanup ---
cap.release()
cv2.destroyAllWindows()
print("Application closed.")